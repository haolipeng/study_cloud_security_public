# Huatuo æºç æ·±åº¦åˆ†æ

> **Huatuo** æ˜¯ç”±æ»´æ»´å¼€æºã€CCFå­µåŒ–çš„äº‘åŸç”Ÿæ“ä½œç³»ç»Ÿå¯è§‚æµ‹æ€§é¡¹ç›®ï¼Œä¸“æ³¨äºæä¾›æ·±åº¦çš„å†…æ ¸çº§å¯è§‚æµ‹èƒ½åŠ›ã€‚æœ¬æ–‡æ¡£ä»æºç å±‚é¢æ·±å…¥åˆ†æå…¶æ¶æ„è®¾è®¡ä¸å®ç°åŸç†ã€‚

---

## ğŸ“‹ ç›®å½•

1. [é¡¹ç›®æ¦‚è§ˆ](#1-é¡¹ç›®æ¦‚è§ˆ)
2. [æ•´ä½“æ¶æ„](#2-æ•´ä½“æ¶æ„)
3. [å†…æ ¸æ€ eBPF ç¨‹åº](#3-å†…æ ¸æ€-ebpf-ç¨‹åº)
4. [äº‹ä»¶ä¼ é€’é€šé“](#4-äº‹ä»¶ä¼ é€’é€šé“)
5. [ç”¨æˆ·æ€å¤„ç†æ¡†æ¶](#5-ç”¨æˆ·æ€å¤„ç†æ¡†æ¶)
6. [å®Œæ•´æ•°æ®æµ](#6-å®Œæ•´æ•°æ®æµ)
7. [æ ¸å¿ƒç»„ä»¶è¯¦è§£](#7-æ ¸å¿ƒç»„ä»¶è¯¦è§£)
8. [æŠ€æœ¯ç‰¹ç‚¹](#8-æŠ€æœ¯ç‰¹ç‚¹)

---

## 1. é¡¹ç›®æ¦‚è§ˆ

### 1.1 é¡¹ç›®å®šä½

Huatuo æ˜¯ä¸€ä¸ªåŸºäº **eBPF** çš„ Linux å†…æ ¸å¯è§‚æµ‹æ€§ç³»ç»Ÿï¼Œæä¾›ï¼š
- ğŸ” **ä½å¼€é”€å†…æ ¸è§‚æµ‹** - æ€§èƒ½å¼€é”€ < 1%
- ğŸ“Š **äº‹ä»¶é©±åŠ¨ä¸Šä¸‹æ–‡æ•è·** - è‡ªåŠ¨è·å–è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
- ğŸ¤– **AutoTracing** - å¯å‘å¼è·Ÿè¸ªç®—æ³•è‡ªåŠ¨å¿«ç…§
- ğŸ“ˆ **æŒç»­æ€§èƒ½å‰–æ** - CPU/å†…å­˜/IO/é”å…¨æ–¹ä½å‰–æ
- ğŸŒ **åˆ†å¸ƒå¼è¿½è¸ª** - ä»¥ç½‘ç»œä¸ºä¸­å¿ƒçš„æœåŠ¡è¯·æ±‚è¿½è¸ª

### 1.2 ç›®å½•ç»“æ„

```
huatuo/
â”œâ”€â”€ bpf/                    # eBPF å†…æ ¸æ€ç¨‹åº (Cä»£ç )
â”‚   â”œâ”€â”€ include/           # å…¬å…±å¤´æ–‡ä»¶
â”‚   â”œâ”€â”€ dropwatch.c        # ç½‘ç»œä¸¢åŒ…ç›‘æ§
â”‚   â”œâ”€â”€ netrecvlat.c       # ç½‘ç»œæ¥æ”¶å»¶è¿Ÿ
â”‚   â”œâ”€â”€ runqlat_tracing.c  # è°ƒåº¦å»¶è¿Ÿè¿½è¸ª
â”‚   â””â”€â”€ ...
â”œâ”€â”€ cmd/huatuo-bamai/      # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ core/                  # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ events/           # äº‹ä»¶å¤„ç†å™¨
â”‚   â”œâ”€â”€ metrics/          # æŒ‡æ ‡é‡‡é›†å™¨
â”‚   â””â”€â”€ autotracing/      # è‡ªåŠ¨è¿½è¸ª
â”œâ”€â”€ internal/             # å†…éƒ¨åŒ…
â”‚   â”œâ”€â”€ bpf/             # BPFç®¡ç†å±‚
â”‚   â”œâ”€â”€ storage/         # å­˜å‚¨å±‚
â”‚   â””â”€â”€ services/        # æœåŠ¡å±‚
â””â”€â”€ pkg/                  # å…¬å…±åŒ…
    â””â”€â”€ tracing/         # è¿½è¸ªæ¡†æ¶
```

---

## 2. æ•´ä½“æ¶æ„

### 2.1 æ¶æ„å›¾

```mermaid
graph TB
    subgraph "Linux Kernel Space"
        A[Tracepoint/Kprobe] --> B[eBPF Programs]
        B --> C[BPF Maps]
        B --> D[Perf Event Array]
    end

    subgraph "User Space"
        D --> E[Perf Event Reader]
        C --> F[Map Poller]

        E --> G[Event Handler]
        F --> H[Metrics Collector]

        G --> I[Storage Layer]
        H --> I

        I --> J[Elasticsearch]
        I --> K[Local Files]
    end

    subgraph "Management Layer"
        L[Tracing Manager] --> M[BPF Manager]
        M --> B
        N[Services API] --> L
    end

    style B fill:#ff9800
    style E fill:#4caf50
    style I fill:#2196f3
```

### 2.2 åˆ†å±‚æ¶æ„

```mermaid
classDiagram
    class KernelLayer {
        <<Kernel Space>>
        +Tracepoints
        +Kprobes/Kretprobes
        +eBPF Programs
        +BPF Maps
    }

    class DataChannelLayer {
        <<Data Transfer>>
        +Perf Event Array
        +Ring Buffer
        +BPF Maps Polling
    }

    class RuntimeLayer {
        <<User Space>>
        +BPF Manager
        +Perf Reader
        +Map Reader
    }

    class BusinessLayer {
        <<Business Logic>>
        +Event Handlers
        +Metrics Collectors
        +AutoTracing
    }

    class StorageLayer {
        <<Storage>>
        +Elasticsearch
        +Local Files
    }

    KernelLayer --> DataChannelLayer
    DataChannelLayer --> RuntimeLayer
    RuntimeLayer --> BusinessLayer
    BusinessLayer --> StorageLayer
```

---

## 3. å†…æ ¸æ€ eBPF ç¨‹åº

### 3.1 eBPF ç¨‹åºåˆ†ç±»

| åˆ†ç±» | ç¨‹åº | åŠŸèƒ½ | æŒ‚è½½ç‚¹ |
|------|------|------|--------|
| **ç½‘ç»œç›‘æ§** | dropwatch.c (181è¡Œ) | TCPä¸¢åŒ…è¿½è¸ª | tracepoint/skb/kfree_skb |
| | netrecvlat.c (177è¡Œ) | ç½‘ç»œæ¥æ”¶å»¶è¿Ÿ | tracepoint/net/netif_receive_skb<br>kprobe/tcp_v4_rcv |
| | netdev_hw.c (37è¡Œ) | ç½‘å¡ç¡¬ä»¶ä¿¡æ¯ | - |
| | lacp.c (25è¡Œ) | LACPåè®®ç›‘æ§ | - |
| **è°ƒåº¦æ€§èƒ½** | runqlat_tracing.c (337è¡Œ) | è°ƒåº¦å»¶è¿Ÿä¸ä¸Šä¸‹æ–‡åˆ‡æ¢ | tracepoint/sched/sched_wakeup<br>raw_tracepoint/sched_switch |
| | softirq.c (81è¡Œ) | è½¯ä¸­æ–­ç›‘æ§ | - |
| | perf.c (61è¡Œ) | æ€§èƒ½äº‹ä»¶ | - |
| **å†…å­˜ç®¡ç†** | memory_free_compact.c (91è¡Œ) | å†…å­˜å‹ç¼©å»¶è¿Ÿ | tracepoint/vmscan/*<br>kprobe/try_to_compact_pages |
| | memory_reclaim.c (56è¡Œ) | å†…å­˜å›æ”¶ | - |
| | oom.c (56è¡Œ) | OOMäº‹ä»¶ | - |
| **ç³»ç»Ÿå¼‚å¸¸** | hungtask.c (33è¡Œ) | æŒ‚èµ·ä»»åŠ¡æ£€æµ‹ | - |
| | softlockup.c (47è¡Œ) | è½¯é”æ£€æµ‹ | - |

### 3.2 å…¸å‹ç¨‹åºè§£æï¼šdropwatch.c

#### 3.2.1 æ•°æ®ç»“æ„å®šä¹‰

```c
// äº‹ä»¶æ•°æ®ç»“æ„
struct perf_event_t {
    u64 tgid_pid;              // è¿›ç¨‹ID
    u32 saddr, daddr;          // æº/ç›®æ ‡IP
    u16 sport, dport;          // æº/ç›®æ ‡ç«¯å£
    u32 seq, ack_seq;          // TCPåºåˆ—å·
    u64 pkt_len;               // åŒ…é•¿åº¦
    u64 stack[PERF_MAX_STACK_DEPTH];  // è°ƒç”¨æ ˆ
    u8 state;                  // TCPçŠ¶æ€
    u8 type;                   // ä¸¢åŒ…ç±»å‹
    char comm[16];             // è¿›ç¨‹å
};

// Perfäº‹ä»¶æ•°ç»„ - ç”¨äºå†…æ ¸åˆ°ç”¨æˆ·æ€ä¼ é€’
struct {
    __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);
    __uint(key_size, sizeof(int));
    __uint(value_size, sizeof(u32));
} perf_events SEC(".maps");

// Per-CPUä¸´æ—¶å­˜å‚¨
struct {
    __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
    __uint(max_entries, 1);
    __type(value, struct perf_event_t);
} dropwatch_stackmap SEC(".maps");
```

#### 3.2.2 æ ¸å¿ƒé€»è¾‘æµç¨‹

```mermaid
sequenceDiagram
    participant K as Kernel
    participant TP as kfree_skb Tracepoint
    participant BPF as eBPF Program
    participant Map as Perf Event Array
    participant User as User Space

    K->>TP: ä¸¢å¼ƒ sk_buff
    TP->>BPF: è§¦å‘ bpf_kfree_skb_prog()

    BPF->>BPF: 1. è¿‡æ»¤æ¡ä»¶æ£€æŸ¥
    Note over BPF: - ä»…å¤„ç† TCP/IPv4<br>- æ£€æŸ¥ socket çŠ¶æ€<br>- Rate Limiting (100/s)

    BPF->>BPF: 2. æå–æ•°æ®
    Note over BPF: - TCP/IPå¤´éƒ¨ä¿¡æ¯<br>- è¿›ç¨‹ä¿¡æ¯<br>- è°ƒç”¨æ ˆ

    BPF->>Map: 3. bpf_perf_event_output()
    Note over Map: Per-CPU Ring Buffer

    Map-->>User: 4. Perf Event Reader
```

#### 3.2.3 å…³é”®ä»£ç ç‰‡æ®µ

```c
SEC("tracepoint/skb/kfree_skb")
int bpf_kfree_skb_prog(struct trace_event_raw_kfree_skb *ctx)
{
    struct sk_buff *skb = ctx->skbaddr;

    // 1ï¸âƒ£ è¿‡æ»¤æ¡ä»¶
    if (ctx->protocol != ETH_P_IP)  // ä»…IPv4
        return 0;

    bpf_probe_read(&iphdr, sizeof(iphdr), skb_network_header(skb));
    if (iphdr.protocol != IPPROTO_TCP)  // ä»…TCP
        return 0;

    // 2ï¸âƒ£ Rate Limiting (100äº‹ä»¶/ç§’)
    if (bpf_ratelimited(&rate))
        return 0;

    // 3ï¸âƒ£ ä»Per-CPUæ•°ç»„è·å–ä¸´æ—¶å­˜å‚¨
    data = bpf_map_lookup_elem(&dropwatch_stackmap, &stackmap_key);

    // 4ï¸âƒ£ å¡«å……äº‹ä»¶æ•°æ®
    data->tgid_pid = bpf_get_current_pid_tgid();
    bpf_get_current_comm(&data->comm, sizeof(data->comm));
    data->saddr = iphdr.saddr;
    data->sport = tcphdr.source;
    // ... æ›´å¤šå­—æ®µ

    // 5ï¸âƒ£ è·å–è°ƒç”¨æ ˆ (æœ€å¤š127å±‚)
    data->stack_size = bpf_get_stack(ctx, data->stack,
                                      sizeof(data->stack), 0);

    // 6ï¸âƒ£ å‘é€åˆ°ç”¨æˆ·æ€ (é€šè¿‡Perf Event Array)
    bpf_perf_event_output(ctx, &perf_events,
                          COMPAT_BPF_F_CURRENT_CPU,
                          data, sizeof(*data));

    return 0;
}
```

### 3.3 å†…æ ¸ç‰ˆæœ¬å…¼å®¹æ€§

Huatuo ä½¿ç”¨ **CO-RE (Compile Once Run Everywhere)** æŠ€æœ¯é€‚é…å¤šç‰ˆæœ¬å†…æ ¸ï¼š

```c
// ç¤ºä¾‹ï¼šå…¼å®¹ä¸åŒå†…æ ¸ç‰ˆæœ¬çš„ socket ç»“æ„
static void sk_get_type_and_protocol(struct sock *sk, u16 *protocol, u16 *type)
{
    // kernel <= 4.18: __sk_flags_offset å­—æ®µå­˜åœ¨
    if (bpf_core_field_exists(sk->__sk_flags_offset)) {
        u32 sk_flags;
        bpf_probe_read(&sk_flags, sizeof(sk_flags), &sk->__sk_flags_offset);
        *protocol = sk_flags >> SK_FL_PROTO_SHIFT;
        *type = sk_flags >> SK_FL_TYPE_SHIFT;
        return;
    }

    // kernel >= 5.10: ç‹¬ç«‹çš„ sk_type, sk_protocol å­—æ®µ
    struct sock___5_10 *sk_new = (struct sock___5_10 *)sk;
    *protocol = BPF_CORE_READ(sk_new, sk_protocol);
    *type = BPF_CORE_READ(sk_new, sk_type);
}
```

### 3.4 æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

#### 3.4.1 Rate Limiting

```c
// bpf/include/bpf_ratelimit.h
BPF_RATELIMIT(rate, 1, 100);  // 1ç§’å†…æœ€å¤š100ä¸ªäº‹ä»¶

if (bpf_ratelimited(&rate))   // è¶…è¿‡é™åˆ¶åˆ™ä¸¢å¼ƒ
    return 0;
```

#### 3.4.2 Per-CPU Maps

```c
// æ¯ä¸ªCPUç‹¬ç«‹çš„æ•°ç»„ï¼Œé¿å…é”ç«äº‰
struct {
    __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
    __uint(max_entries, 1);
    __type(value, struct perf_event_t);
} dropwatch_stackmap SEC(".maps");
```

---

## 4. äº‹ä»¶ä¼ é€’é€šé“

### 4.1 Perf Event Array æœºåˆ¶

```mermaid
graph LR
    subgraph "Kernel Space - Per CPU"
        A1[CPU 0<br>Ring Buffer]
        A2[CPU 1<br>Ring Buffer]
        A3[CPU N<br>Ring Buffer]
    end

    subgraph "Shared Memory (mmap)"
        B[Perf Event Array]
    end

    subgraph "User Space"
        C[Perf Reader<br>epollç›‘å¬]
        D[Event Handler]
    end

    A1 --> B
    A2 --> B
    A3 --> B
    B --> C
    C --> D

    style B fill:#ff9800
    style C fill:#4caf50
```

### 4.2 å®ç°ç»†èŠ‚

#### 4.2.1 å†…æ ¸æ€å‘é€äº‹ä»¶

```c
// å‘é€äº‹ä»¶åˆ° Perf Event Array
bpf_perf_event_output(
    ctx,                        // ä¸Šä¸‹æ–‡
    &perf_events,              // Perf Event Array Map
    COMPAT_BPF_F_CURRENT_CPU,  // å½“å‰CPU (é¿å…è·¨CPUåŒæ­¥)
    data,                       // äº‹ä»¶æ•°æ®æŒ‡é’ˆ
    sizeof(*data)              // æ•°æ®å¤§å°
);
```

#### 4.2.2 ç”¨æˆ·æ€åˆ›å»º Reader

```go
// internal/bpf/perf_event_reader_default.go

func newPerfEventReader(ctx context.Context, array *ebpf.Map,
                        perCPUBuffer int) (PerfEventReader, error) {
    // ä½¿ç”¨ Cilium eBPF åº“åˆ›å»º Reader
    // perCPUBuffer = 8192 é¡µ (çº¦32MB per CPU)
    rd, err := perf.NewReader(array, perCPUBuffer)
    if err != nil {
        return nil, fmt.Errorf("can't create perf reader: %w", err)
    }

    readerCtx, cancel := context.WithCancel(ctx)
    return &perfEventReader{
        ctx:       readerCtx,
        rd:        rd,
        cancelCtx: cancel,
    }, nil
}
```

#### 4.2.3 è¯»å–äº‹ä»¶

```go
func (r *perfEventReader) ReadInto(pdata any) error {
    for {
        select {
        case <-r.ctx.Done():
            return types.ErrExitByCancelCtx
        default:
            // è®¾ç½®100msè½®è¯¢è¶…æ—¶
            r.rd.SetDeadline(time.Now().Add(100 * time.Millisecond))

            // ä» Ring Buffer è¯»å–
            record, err := r.rd.Read()
            if err != nil {
                if errors.Is(err, os.ErrDeadlineExceeded) {
                    continue  // è¶…æ—¶é‡è¯•
                }
                return err
            }

            if record.LostSamples != 0 {
                continue  // è·³è¿‡ä¸¢å¤±çš„æ ·æœ¬
            }

            // äºŒè¿›åˆ¶ååºåˆ—åŒ– (Zero-Copy)
            err = binary.Read(
                bytes.NewBuffer(record.RawSample),
                binary.NativeEndian,
                pdata
            )
            return err
        }
    }
}
```

### 4.3 æ€§èƒ½ç‰¹ç‚¹

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **Zero-Copy** | mmap å…±äº«å†…å­˜ï¼Œé¿å…æ•°æ®æ‹·è´ |
| **Per-CPU Buffer** | æ¯CPUç‹¬ç«‹Ring Bufferï¼Œæ— é”ç«äº‰ |
| **Batch Processing** | ç”¨æˆ·æ€100msè½®è¯¢æ‰¹é‡å¤„ç† |
| **Binary Protocol** | åŸç”ŸäºŒè¿›åˆ¶æ ¼å¼ï¼Œæ— åºåˆ—åŒ–å¼€é”€ |
| **Overflow Handling** | è®°å½• LostSamples æ•°é‡ |

---

## 5. ç”¨æˆ·æ€å¤„ç†æ¡†æ¶

### 5.1 åˆ†å±‚æ¶æ„

```mermaid
classDiagram
    class BPFManager {
        +LoadBpf(name, consts) BPF
        +InitBpfManager()
        +CloseBpfManager()
    }

    class BPF {
        +Attach() error
        +Detach() error
        +EventPipeByName(mapName) Reader
        +DumpMapByName(mapName) []MapItem
        +Close() error
    }

    class TracingManager {
        +tracingEvents map[string]*EventTracing
        +MgrTracingEventStartAll()
        +MgrTracingEventStopAll()
    }

    class EventTracing {
        +ic ITracingEvent
        +Start() error
        +Stop()
        -doStart()
    }

    class ITracingEvent {
        <<interface>>
        +Start(ctx) error
    }

    class DropWatchTracing {
        +Start(ctx) error
        -formatEvent() *Data
        -ignore() bool
    }

    class StorageLayer {
        +Save(name, region, time, data)
        +Elasticsearch
        +LocalFile
    }

    BPFManager --> BPF
    TracingManager --> EventTracing
    EventTracing --> ITracingEvent
    ITracingEvent <|.. DropWatchTracing
    DropWatchTracing --> BPF
    DropWatchTracing --> StorageLayer
```

### 5.2 å¯åŠ¨æµç¨‹

```mermaid
sequenceDiagram
    participant Main as main()
    participant Mgr as TracingManager
    participant ET as EventTracing
    participant DW as DropWatchTracing
    participant BPF as BPF Manager
    participant Kernel as Kernel

    Main->>Mgr: NewMgrTracingEvent(blacklist)
    Note over Mgr: æ³¨å†Œæ‰€æœ‰Tracer<br>(dropwatch, netrecvlat, ...)

    Main->>Mgr: MgrTracingEventStartAll()

    loop éå†æ‰€æœ‰Tracer
        Mgr->>ET: Start()
        ET->>ET: å¯åŠ¨ Goroutine

        loop å®šæœŸé‡å¯ (æ¯10ç§’)
            ET->>DW: Start(ctx)
            DW->>BPF: LoadBpf("dropwatch.o")
            BPF->>Kernel: Load eBPF Programs

            DW->>BPF: AttachAndEventPipe("perf_events", 8192)
            BPF->>Kernel: Attach to Tracepoints
            BPF-->>DW: Return PerfEventReader

            loop è¯»å–äº‹ä»¶
                DW->>BPF: reader.ReadInto(&event)
                BPF-->>Kernel: Poll Perf Ring Buffer
                Kernel-->>BPF: Return Event Data
                BPF-->>DW: Unmarshal Event

                DW->>DW: formatEvent()
                DW->>DW: ignore() check

                alt Not Ignored
                    DW->>Storage: Save(event)
                end
            end
        end
    end
```

### 5.3 æ ¸å¿ƒä»£ç å®ç°

#### 5.3.1 Tracing Manager

```go
// pkg/tracing/manager.go
type MgrTracingEvent struct {
    tracingEvents map[string]*EventTracing  // æ‰€æœ‰æ³¨å†Œçš„Tracer
    mu            sync.Mutex
    blackListed   []string                  // é»‘åå•
}

func NewMgrTracingEvent(blackListed []string) (*MgrTracingEvent, error) {
    // åˆ›å»ºæ‰€æœ‰å·²æ³¨å†Œçš„Tracerå®ä¾‹
    tracings, err := NewRegister(blackListed)
    if err != nil {
        return nil, err
    }

    tracingEvents := make(map[string]*EventTracing)
    for key, trace := range tracings {
        if trace.Flag&FlagTracing == 0 {
            continue  // è·³è¿‡éTracingç±»å‹
        }
        tracingEvents[key] = NewTracingEvent(trace, key)
    }

    return &MgrTracingEvent{
        tracingEvents: tracingEvents,
        blackListed:   blackListed,
    }, nil
}

func (mgr *MgrTracingEvent) MgrTracingEventStartAll() error {
    for name := range mgr.tracingEvents {
        if err := mgr.MgrTracingEventStart(name); err != nil {
            return err
        }
    }
    return nil
}
```

#### 5.3.2 Event Tracing ç”Ÿå‘½å‘¨æœŸ

```go
// pkg/tracing/tracing.go
type EventTracing struct {
    ic        ITracingEvent      // å…·ä½“å®ç° (å¦‚dropwatch)
    name      string
    interval  int                // é‡å¯é—´éš” (ç§’)
    hitCount  int
    cancelCtx context.CancelFunc
    exit      bool
    isRunning bool
}

func (c *EventTracing) Start() error {
    c.isRunning = true
    c.exit = false

    // å¯åŠ¨ Goroutine
    go func() {
        for !c.exit {
            c.doStart()  // æ‰§è¡Œä¸€æ¬¡è¿½è¸ª
            c.hitCount++

            if c.exit {
                break
            }

            // é—´éš”åé‡å¯ (é»˜è®¤10ç§’)
            time.Sleep(time.Duration(c.interval) * time.Second)
        }

        c.isRunning = false
        log.Infof("%s: tracing goroutine exited", c.name)
    }()

    return nil
}

func (c *EventTracing) doStart() {
    ctx, cancel := context.WithCancel(context.Background())
    c.cancelCtx = cancel
    defer c.cancelCtx()

    // è°ƒç”¨å…·ä½“å®ç°çš„ Start æ–¹æ³•
    if err := c.ic.Start(ctx); err != nil {
        if !errors.Is(err, types.ErrExitByCancelCtx) {
            log.Errorf("start tracing %s: %v", c.name, err)
        }
    }
}
```

#### 5.3.3 DropWatch å®ç°

```go
// core/events/dropwatch.go
type dropWatchTracing struct{}

func init() {
    // æ³¨å†Œåˆ°å…¨å±€Registry
    tracing.RegisterEventTracing(tracerName, newDropWatch)
}

func (c *dropWatchTracing) Start(ctx context.Context) error {
    // 1ï¸âƒ£ åŠ è½½ BPF ç¨‹åº
    b, err := bpf.LoadBpf(bpf.ThisBpfOBJ(), nil)
    if err != nil {
        return fmt.Errorf("load bpf: %w", err)
    }
    defer b.Close()

    childCtx, cancel := context.WithCancel(ctx)
    defer cancel()

    // 2ï¸âƒ£ Attach å¹¶åˆ›å»ºäº‹ä»¶ç®¡é“
    reader, err := b.AttachAndEventPipe(childCtx, "perf_events", 8192)
    if err != nil {
        return fmt.Errorf("attach and event pipe: %w", err)
    }
    defer reader.Close()

    // 3ï¸âƒ£ ç›‘å¬ Context å–æ¶ˆä¿¡å·
    b.WaitDetachByBreaker(childCtx, cancel)

    // 4ï¸âƒ£ äº‹ä»¶å¾ªç¯
    for {
        select {
        case <-childCtx.Done():
            log.Info("dropwatch: tracer is stopped.")
            return nil
        default:
            var event perfEventT

            // 5ï¸âƒ£ é˜»å¡è¯»å–äº‹ä»¶
            if err := reader.ReadInto(&event); err != nil {
                return fmt.Errorf("failed to read from perf: %w", err)
            }

            // 6ï¸âƒ£ æ ¼å¼åŒ–äº‹ä»¶
            tracerData := c.formatEvent(&event)

            // 7ï¸âƒ£ è¿‡æ»¤ä¸éœ€è¦çš„äº‹ä»¶
            if c.ignore(tracerData) {
                log.Debugf("ignore dropwatch data: %v", tracerData)
                continue
            }

            // 8ï¸âƒ£ ä¿å­˜åˆ°å­˜å‚¨å±‚
            storage.Save(tracerName, "", time.Now(), tracerData)
        }
    }
}
```

#### 5.3.4 äº‹ä»¶æ ¼å¼åŒ–

```go
func (c *dropWatchTracing) formatEvent(event *perfEventT) *DropWatchTracingData {
    // IPåœ°å€è½¬æ¢
    saddr := netutil.InetNtop(event.Saddr).String()
    daddr := netutil.InetNtop(event.Daddr).String()

    // DNSåå‘è§£æ (hostname)
    srcHostname := "<nil>"
    h, err := net.LookupAddr(saddr)
    if err == nil && len(h) > 0 {
        srcHostname = h[0]
    }

    // è§£æå†…æ ¸è°ƒç”¨æ ˆ (é€šè¿‡ /proc/kallsyms)
    stacks := strings.Join(
        symbol.DumpKernelBackTrace(event.Stack[:], 127).BackTrace,
        "\n"
    )

    return &DropWatchTracingData{
        Type:          typeMap[event.Type],
        Comm:          strings.TrimRight(string(event.Comm[:]), "\x00"),
        Pid:           event.TgidPid >> 32,
        Saddr:         saddr,
        Sport:         netutil.InetNtohs(event.Sport),
        State:         tcpstateMap[event.State],
        Stack:         stacks,
        // ... æ›´å¤šå­—æ®µ
    }
}
```

#### 5.3.5 æ™ºèƒ½è¿‡æ»¤

```go
func (c *dropWatchTracing) ignore(data *DropWatchTracingData) bool {
    stack := strings.Split(data.Stack, "\n")

    // å¿½ç•¥ CLOSE_WAIT çŠ¶æ€ä¸‹çš„ skb_rbtree_purge
    if data.State == "CLOSE_WAIT" {
        if len(stack) >= 3 &&
           strings.HasPrefix(stack[2], "skb_rbtree_purge/") {
            return true
        }
    }

    // å¿½ç•¥ neigh_invalidate (å¯é…ç½®)
    if conf.Get().Tracing.Dropwatch.IgnoreNeighInvalidate {
        if len(stack) >= 3 &&
           strings.HasPrefix(stack[2], "neigh_invalidate/") {
            return true
        }
    }

    // å¿½ç•¥ç‰¹å®šç½‘å¡é©±åŠ¨çš„æ­£å¸¸ä¸¢åŒ…
    if len(stack) >= 3 &&
       (strings.HasPrefix(stack[2], "bnxt_tx_int/") ||
        strings.HasPrefix(stack[2], "__bnxt_tx_int/")) {
        return true
    }

    return false
}
```

### 5.4 BPF ç®¡ç†å±‚

```go
// internal/bpf/bpf_default.go
type defaultBPF struct {
    name            string
    mapSpecs        map[uint32]mapSpec        // Map ID -> Map
    programSpecs    map[uint32]programSpec    // Prog ID -> Program
    mapName2IDs     map[string]uint32         // Name -> Map ID
    programName2IDs map[string]uint32         // Name -> Prog ID
    innerPerfEvent  *perfEventPMU
}

func LoadBpf(bpfName string, consts map[string]any) (BPF, error) {
    // 1. ä»æ–‡ä»¶åŠ è½½ ELF
    f, err := os.Open(filepath.Join(DefaultBpfObjDir, bpfName))
    defer f.Close()

    // 2. è§£æ eBPF Collection
    specs, err := ebpf.LoadCollectionSpecFromReader(f)

    // 3. é‡å†™å¸¸é‡ (å¦‚é…ç½®å‚æ•°)
    if consts != nil {
        specs.RewriteConstants(consts)
    }

    // 4. åŠ è½½åˆ°å†…æ ¸
    coll, err := ebpf.NewCollection(specs)

    // 5. å…‹éš† Maps å’Œ Programs (é¿å…è¢«è‡ªåŠ¨å…³é—­)
    for name, m := range coll.Maps {
        info, _ := m.Info()
        id, _ := info.ID()
        bMap, _ := m.Clone()
        b.mapSpecs[uint32(id)] = mapSpec{name: name, bMap: bMap}
    }

    for name, p := range coll.Programs {
        info, _ := p.Info()
        id, _ := info.ID()
        bProg, _ := p.Clone()
        b.programSpecs[uint32(id)] = programSpec{
            name: name,
            bProg: bProg,
            links: make(map[string]link.Link),
        }
    }

    return b, nil
}

func (b *defaultBPF) AttachAndEventPipe(ctx context.Context,
                                        mapName string,
                                        perCPUBuffer uint32) (PerfEventReader, error) {
    // 1. Attach æ‰€æœ‰ç¨‹åº
    if err := b.Attach(); err != nil {
        return nil, err
    }

    // 2. åˆ›å»º Perf Event Reader
    return b.EventPipeByName(ctx, mapName, perCPUBuffer)
}
```

---

## 6. å®Œæ•´æ•°æ®æµ

### 6.1 ç«¯åˆ°ç«¯æ•°æ®æµ

```mermaid
graph TB
    subgraph "Linux Kernel"
        A1[TCP Stack] -->|kfree_skb| A2[Tracepoint]
        A2 --> A3[eBPF dropwatch.c]
        A3 -->|Filter & Extract| A4[Perf Event Array]
    end

    subgraph "Shared Memory"
        A4 --> B1[Per-CPU Ring Buffer 0]
        A4 --> B2[Per-CPU Ring Buffer N]
    end

    subgraph "User Space Runtime"
        B1 --> C1[Perf Reader]
        B2 --> C1
        C1 -->|ReadInto| C2[dropWatchTracing]
    end

    subgraph "Business Logic"
        C2 -->|formatEvent| D1[IP Address Conversion]
        C2 -->|formatEvent| D2[Stack Symbolization]
        C2 -->|ignore| D3[Smart Filtering]
        D1 --> E1[DropWatchTracingData]
        D2 --> E1
        D3 --> E1
    end

    subgraph "Storage Layer"
        E1 --> F1{Storage Router}
        F1 -->|JSON| F2[Elasticsearch]
        F1 -->|JSON Lines| F3[Local Rotated Files]
    end

    style A3 fill:#ff9800
    style C1 fill:#4caf50
    style E1 fill:#2196f3
    style F1 fill:#9c27b0
```

### 6.2 æ—¶åºå›¾

```mermaid
sequenceDiagram
    autonumber
    participant TCP as TCP Stack
    participant TP as kfree_skb
    participant BPF as eBPF Program
    participant RB as Ring Buffer
    participant PR as Perf Reader
    participant DW as DropWatch Handler
    participant SYM as Symbol Resolver
    participant ES as Elasticsearch

    TCP->>TP: Drop packet
    activate TP
    TP->>BPF: Trigger bpf_kfree_skb_prog()
    activate BPF

    BPF->>BPF: Filter (TCP/IPv4, State, Rate)
    BPF->>BPF: Extract (IP, Port, Stack)
    BPF->>RB: bpf_perf_event_output()
    deactivate BPF
    deactivate TP

    Note over RB: Buffered in<br>Per-CPU Ring

    PR->>RB: Poll with epoll (100ms timeout)
    activate PR
    RB-->>PR: Return raw bytes
    PR->>PR: binary.Read() unmarshal
    PR-->>DW: perfEventT struct
    deactivate PR

    activate DW
    DW->>DW: InetNtop (IP conversion)
    DW->>SYM: DumpKernelBackTrace()
    activate SYM
    SYM->>SYM: Lookup /proc/kallsyms
    SYM-->>DW: Human-readable stack
    deactivate SYM

    DW->>DW: ignore() filtering

    alt Not Ignored
        DW->>ES: storage.Save()
        activate ES
        ES->>ES: JSON serialization
        ES->>ES: Bulk indexing
        deactivate ES
    else Ignored
        DW->>DW: Drop silently
    end
    deactivate DW
```

---

## 7. æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 7.1 æ³¨å†Œæœºåˆ¶

```go
// pkg/tracing/register.go
var (
    eventTracingRegistry  = make(map[string]EventTracingConstructor)
    metricTracingRegistry = make(map[string]MetricTracingConstructor)
)

type EventTracingConstructor func() (*EventTracingAttr, error)

// åœ¨ init() ä¸­æ³¨å†Œ
func RegisterEventTracing(name string, constructor EventTracingConstructor) {
    eventTracingRegistry[name] = constructor
}

// åˆ›å»ºæ‰€æœ‰å®ä¾‹
func NewRegister(blackListed []string) (map[string]*EventTracingAttr, error) {
    tracings := make(map[string]*EventTracingAttr)

    for name, constructor := range eventTracingRegistry {
        if slices.Contains(blackListed, name) {
            continue
        }

        attr, err := constructor()
        if err != nil {
            return nil, err
        }
        tracings[name] = attr
    }

    return tracings, nil
}
```

### 7.2 å­˜å‚¨æŠ½è±¡å±‚

```go
// internal/storage/storage.go
type Storage interface {
    Write(index, region string, timestamp time.Time, data any) error
    Close() error
}

var defaultStorages []Storage

func Save(index, region string, timestamp time.Time, data any) {
    for _, storage := range defaultStorages {
        if err := storage.Write(index, region, timestamp, data); err != nil {
            log.Errorf("storage write error: %v", err)
        }
    }
}

func InitDefaultClients(ctx *InitContext) error {
    // Elasticsearch
    if len(ctx.EsAddresses) > 0 {
        es, err := NewElasticsearch(ctx)
        defaultStorages = append(defaultStorages, es)
    }

    // Local File (JSON Lines with rotation)
    if ctx.LocalPath != "" {
        local, err := NewLocalFile(ctx)
        defaultStorages = append(defaultStorages, local)
    }

    return nil
}
```

### 7.3 ç¬¦å·è§£æ

```go
// internal/symbol/ksymbols.go
type KernelSymbol struct {
    Addr     uint64
    Symbol   string
    Module   string
}

var ksymCache map[uint64]*KernelSymbol

func DumpKernelBackTrace(stack []uint64, depth int) *BackTrace {
    bt := &BackTrace{BackTrace: make([]string, 0, depth)}

    for i := 0; i < depth; i++ {
        addr := stack[i]
        if addr == 0 {
            break
        }

        sym := lookupKsym(addr)
        if sym != nil {
            bt.BackTrace = append(bt.BackTrace,
                fmt.Sprintf("%s/%x", sym.Symbol, addr))
        } else {
            bt.BackTrace = append(bt.BackTrace,
                fmt.Sprintf("unknown/%x", addr))
        }
    }

    return bt
}
```

---

## 8. æŠ€æœ¯ç‰¹ç‚¹

### 8.1 æ ¸å¿ƒä¼˜åŠ¿

| ç‰¹æ€§ | å®ç°æ–¹å¼ | ä¼˜åŠ¿ |
|------|----------|------|
| **ä½å¼€é”€** | eBPF JIT + Per-CPU Maps | < 1% CPUå¼€é”€ |
| **é›¶ä¾µå…¥** | Kernel Tracepoint/Kprobe | æ— éœ€ä¿®æ”¹åº”ç”¨ä»£ç  |
| **å®æ—¶æ€§** | Perf Event Array | å¾®ç§’çº§äº‹ä»¶å»¶è¿Ÿ |
| **å¯æ‰©å±•** | æ’ä»¶å¼æ³¨å†Œæœºåˆ¶ | è½»æ¾æ·»åŠ æ–°Tracer |
| **å†…æ ¸å…¼å®¹** | CO-RE (BTF) | ä¸€æ¬¡ç¼–è¯‘ï¼Œå¤šç‰ˆæœ¬è¿è¡Œ |
| **æ™ºèƒ½è¿‡æ»¤** | Rate Limiting + è§„åˆ™å¼•æ“ | å‡å°‘å™ªéŸ³äº‹ä»¶ |

### 8.2 é€‚ç”¨åœºæ™¯

- âœ… **ç”Ÿäº§ç¯å¢ƒæ•…éšœè¯Šæ–­** - å®æ—¶æ•è·å¼‚å¸¸ä¸Šä¸‹æ–‡
- âœ… **æ€§èƒ½åˆ†æä¸ä¼˜åŒ–** - CPU/å†…å­˜/ç½‘ç»œçƒ­ç‚¹åˆ†æ
- âœ… **SLOç›‘æ§** - è°ƒåº¦å»¶è¿Ÿ/ç½‘ç»œå»¶è¿Ÿç­‰æŒ‡æ ‡
- âœ… **å®‰å…¨å®¡è®¡** - ç³»ç»Ÿè°ƒç”¨è¿½è¸ª
- âœ… **å®¹å™¨ç›‘æ§** - Kubernetesé›†æˆ

### 8.3 ä¸ä¼ ç»Ÿæ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | å¼€é”€ | å†…æ ¸ç‰ˆæœ¬ | åŠ¨æ€æ€§ | å®‰å…¨æ€§ |
|------|------|----------|--------|--------|
| **Huatuo (eBPF)** | < 1% | 4.x+ | âœ… | âœ… |
| SystemTap | 5-10% | All | âœ… | âš ï¸ |
| ftrace | 2-5% | All | âŒ | âœ… |
| perf | 1-3% | All | âŒ | âœ… |
| LTTng | 1-2% | All | âŒ | âœ… |

---

## 9. æ€»ç»“

Huatuo é€šè¿‡ **eBPF + Perf Event Array** æ„å»ºäº†é«˜æ•ˆçš„å†…æ ¸å¯è§‚æµ‹æ€§ç³»ç»Ÿï¼š

1. **å†…æ ¸æ€** - 16ä¸ªeBPFç¨‹åºè¦†ç›–ç½‘ç»œã€è°ƒåº¦ã€å†…å­˜ç­‰å­ç³»ç»Ÿ
2. **ä¼ é€’é€šé“** - Perf Event Arrayå®ç°é›¶æ‹·è´ã€Per-CPUäº‹ä»¶ä¼ é€’
3. **ç”¨æˆ·æ€** - æ’ä»¶å¼æ¡†æ¶æ”¯æŒçµæ´»çš„äº‹ä»¶å¤„ç†ä¸å­˜å‚¨

æ ¸å¿ƒåˆ›æ–°ï¼š
- ğŸ¯ **CO-REæŠ€æœ¯** - å®ç°å†…æ ¸ç‰ˆæœ¬å…¼å®¹æ€§
- ğŸš€ **æ™ºèƒ½è¿‡æ»¤** - Rate Limiting + è§„åˆ™å¼•æ“å‡å°‘å™ªéŸ³
- ğŸ” **ä¸Šä¸‹æ–‡è¿˜åŸ** - è°ƒç”¨æ ˆç¬¦å·åŒ–ã€DNSåå‘è§£æ
- ğŸ“¦ **æ¨¡å—åŒ–è®¾è®¡** - æ˜“äºæ‰©å±•æ–°çš„ç›‘æ§èƒ½åŠ›

é€‚åˆåœ¨ç”Ÿäº§ç¯å¢ƒå¤§è§„æ¨¡éƒ¨ç½²ï¼Œä¸ºäº‘åŸç”Ÿç³»ç»Ÿæä¾›æ·±åº¦å¯è§‚æµ‹æ€§æ”¯æ’‘ã€‚

---

**License**: Apache 2.0
**Repository**: https://github.com/ccfos/huatuo
**Documentation**: https://huatuo.tech

---

## 10. BPF ç¨‹åºé€ä¸ªæ·±åº¦åˆ†æ

### 10.1 ç½‘ç»œç›‘æ§ç±»

#### 10.1.1 netrecvlat.c - ç½‘ç»œæ¥æ”¶å»¶è¿Ÿç›‘æ§

**åŠŸèƒ½**: åœ¨ç½‘ç»œæ•°æ®åŒ…æ¥æ”¶è·¯å¾„çš„ä¸‰ä¸ªå…³é”®ç‚¹ç›‘æ§å»¶è¿Ÿ

**æŒ‚è½½ç‚¹**:
- `tracepoint/net/netif_receive_skb` - ç½‘å¡æ¥æ”¶å±‚
- `kprobe/tcp_v4_rcv` - TCPåè®®æ ˆå¤„ç†å±‚
- `tracepoint/skb/skb_copy_datagram_iovec` - æ•°æ®æ‹·è´åˆ°ç”¨æˆ·ç©ºé—´

**æ ¸å¿ƒæ•°æ®ç»“æ„**:
```c
struct perf_event_t {
    char comm[16];        // è¿›ç¨‹å
    u64 latency;          // å»¶è¿Ÿæ—¶é—´(çº³ç§’)
    u64 tgid_pid;        // è¿›ç¨‹ID
    u64 pkt_len;         // åŒ…é•¿åº¦
    u16 sport, dport;    // æº/ç›®æ ‡ç«¯å£
    u32 saddr, daddr;    // æº/ç›®æ ‡IP
    u32 seq, ack_seq;    // TCPåºåˆ—å·
    u8 state;            // TCPçŠ¶æ€
    u8 where;            // å»¶è¿Ÿå‘ç”Ÿä½ç½®
};

enum skb_rcv_where {
    TO_NETIF_RCV,      // ç½‘å¡æ¥æ”¶å±‚ (é˜ˆå€¼5ms)
    TO_TCPV4_RCV,      // TCPå¤„ç†å±‚ (é˜ˆå€¼10ms)
    TO_USER_COPY,      // ç”¨æˆ·æ‹·è´å±‚ (é˜ˆå€¼115ms)
};
```

**å…³é”®å®ç°**:
```c
// 1. è®¡ç®—å»¶è¿Ÿï¼šå½“å‰æ—¶é—´ - skb->tstamp (å†…æ ¸æ—¶é—´æˆ³)
static inline u64 delta_now_skb_tstamp(struct sk_buff *skb)
{
    u64 tstamp = BPF_CORE_READ(skb, tstamp);
    if (!tstamp) return 0;  // è™šæ‹Ÿè®¾å¤‡å¯èƒ½æ²¡æœ‰æ—¶é—´æˆ³
    
    return bpf_ktime_get_ns() + mono_wall_offset - tstamp;
}

// 2. ä¸‰ä¸ªç›‘æ§ç‚¹çš„å®ç°æ¨¡å¼
SEC("tracepoint/net/netif_receive_skb")
int netif_receive_skb_prog(...) {
    delta = delta_now_skb_tstamp(skb);
    if (delta < to_netif)  // 5msé˜ˆå€¼è¿‡æ»¤
        return 0;
    
    fill_and_output_event(args, skb, TO_NETIF_RCV);
}
```

**è®¾è®¡äº®ç‚¹**:
1. **åˆ†å±‚ç›‘æ§**: ç²¾ç¡®å®šä½å»¶è¿Ÿå‘ç”Ÿåœ¨ç½‘ç»œæ ˆçš„å“ªä¸€å±‚
2. **åŠ¨æ€é˜ˆå€¼**: å¯é€šè¿‡å¸¸é‡é‡å†™è°ƒæ•´å»¶è¿Ÿé˜ˆå€¼ (volatile const)
3. **æ—¶é’Ÿæ ¡å‡†**: mono_wall_offset ç”¨äº CLOCK_MONOTONIC ä¸ CLOCK_REALTIME è½¬æ¢

**æ€§èƒ½ä¼˜åŒ–**:
- Rate Limiting: 100äº‹ä»¶/ç§’
- ä½¿ç”¨ `likely()` / `unlikely()` ä¼˜åŒ–åˆ†æ”¯é¢„æµ‹
- ä»…åœ¨ TO_USER_COPY é˜¶æ®µè¯»å–è¿›ç¨‹ä¿¡æ¯ (å‡å°‘å¼€é”€)

---

#### 10.1.2 netdev_hw.c - ç½‘å¡ç¡¬ä»¶ä¸¢åŒ…ç»Ÿè®¡

**åŠŸèƒ½**: ç›‘æ§ç½‘å¡ç¡¬ä»¶å±‚é¢çš„æ¥æ”¶ä¸¢åŒ…ç»Ÿè®¡

**æŒ‚è½½ç‚¹**:
- `kprobe/carrier_down_count_show` - ç½‘å¡çŠ¶æ€å˜åŒ–æ—¶è§¦å‘

**æ ¸å¿ƒå®ç°**:
```c
// Hash Map: ifindex -> rx_dropped count
struct {
    __uint(type, BPF_MAP_TYPE_HASH);
    __uint(max_entries, 64);      // æ”¯æŒ64ä¸ªç½‘å¡
    __type(key, u32);             // ç½‘å¡ç´¢å¼•
    __type(value, u64);           // ä¸¢åŒ…è®¡æ•°
} rx_sw_dropped_stats SEC(".maps");

SEC("kprobe/carrier_down_count_show")
int BPF_KPROBE(carrier_down_count_show, struct device *dev)
{
    // é€šè¿‡ container_of ä» device è·å– net_device
    struct net_device *netdev = container_of(dev, struct net_device, dev);
    u32 key   = BPF_CORE_READ(netdev, ifindex);
    u64 value = BPF_CORE_READ(netdev, rx_dropped.counter);
    
    bpf_map_update_elem(&rx_sw_dropped_stats, &key, &value, COMPAT_BPF_ANY);
    return 0;
}
```

**ç‰¹ç‚¹**:
- æç®€å®ç° (ä»…37è¡Œ)
- ä½¿ç”¨ BPF Hash Map (éäº‹ä»¶é©±åŠ¨ï¼Œç”¨æˆ·æ€è½®è¯¢è¯»å–)
- `container_of` å®å®ç°ç»“æ„ä½“æˆå‘˜åˆ°æ•´ä½“çš„è½¬æ¢

---

#### 10.1.3 lacp.c - LACP åè®®ç›‘æ§

**åŠŸèƒ½**: ç›‘æ§ LACP (Link Aggregation Control Protocol) é“¾è·¯èšåˆåè®®çŠ¶æ€å˜åŒ–

**æŒ‚è½½ç‚¹**:
- `kprobe/ad_disable_collecting_distributing` - LACP ç¦ç”¨äº‹ä»¶

**æ ¸å¿ƒå®ç°**:
```c
SEC("kprobe/ad_disable")
int ad_disable(struct pt_regs *ctx)
{
    // ä»…é€šçŸ¥ç”¨æˆ·ç©ºé—´ï¼Œä¸ä¼ é€’å…·ä½“æ•°æ®
    // å› ä¸º LACP æ˜¯å†…æ ¸æ¨¡å—(ko)ï¼Œè€å†…æ ¸ä¸æ”¯æŒ CO-RE é‡å®šä½
    u64 nothing = 0;
    bpf_perf_event_output(ctx, &ad_event_map, 
                          COMPAT_BPF_F_CURRENT_CPU,
                          &nothing, sizeof(nothing));
    return 0;
}
```

**è®¾è®¡åŸå› **:
- LACP å®ç°åœ¨å†…æ ¸æ¨¡å— (bonding.ko)ï¼Œä¸åœ¨ vmlinux
- è€å†…æ ¸ä¸æ”¯æŒå¯¹å†…æ ¸æ¨¡å—çš„ CO-RE é‡å®šä½
- ä»…å‘é€äº‹ä»¶é€šçŸ¥ï¼Œå…·ä½“ä¿¡æ¯ç”±ç”¨æˆ·æ€é€šè¿‡ sysfs è¯»å–

---

### 10.2 è°ƒåº¦æ€§èƒ½ç±»

#### 10.2.1 softirq.c - è½¯ä¸­æ–­å»¶è¿Ÿç›‘æ§

**åŠŸèƒ½**: ç›‘æ§è½¯ä¸­æ–­ä»è§¦å‘ (raise) åˆ°æ‰§è¡Œ (entry) çš„å»¶è¿Ÿåˆ†å¸ƒ

**æŒ‚è½½ç‚¹**:
- `tracepoint/irq/softirq_raise` - è½¯ä¸­æ–­è§¦å‘
- `tracepoint/irq/softirq_entry` - è½¯ä¸­æ–­å¼€å§‹æ‰§è¡Œ

**æ ¸å¿ƒæ•°æ®ç»“æ„**:
```c
enum lat_zone {
    LAT_ZONE0 = 0,   // 0 ~ 10us
    LAT_ZONE1,       // 10us ~ 100us
    LAT_ZONE2,       // 100us ~ 1ms
    LAT_ZONE3,       // 1ms ~ inf
    LAT_ZONE_MAX,
};

struct softirq_lat {
    u64 timestamp;                      // raiseæ—¶åˆ»
    u64 total_latency[LAT_ZONE_MAX];   // å„åŒºé—´è®¡æ•°
};

// Per-CPU æ•°ç»„ï¼šæ¯ç§è½¯ä¸­æ–­ç‹¬ç«‹ç»Ÿè®¡
struct {
    __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
    __uint(max_entries, NR_SOFTIRQS_MAX);  // 16ç§è½¯ä¸­æ–­
    __type(key, u32);
    __type(value, struct softirq_lat);
} softirq_percpu_lats SEC(".maps");
```

**å®ç°é€»è¾‘**:
```c
// 1. softirq_raise: è®°å½•è§¦å‘æ—¶é—´æˆ³
SEC("tracepoint/irq/softirq_raise")
int probe_softirq_raise(struct trace_event_raw_softirq *ctx)
{
    u32 vec = ctx->vec;  // è½¯ä¸­æ–­ç±»å‹ (0-15)
    lat = bpf_map_lookup_elem(&softirq_percpu_lats, &vec);
    
    if (!lat) {
        // é¦–æ¬¡åˆå§‹åŒ–
        struct softirq_lat lat_init = {
            .timestamp = bpf_ktime_get_ns(),
        };
        bpf_map_update_elem(&softirq_percpu_lats, &vec, &lat_init, ...);
    } else {
        lat->timestamp = bpf_ktime_get_ns();
    }
}

// 2. softirq_entry: è®¡ç®—å»¶è¿Ÿå¹¶åˆ†åŒºé—´ç»Ÿè®¡
SEC("tracepoint/irq/softirq_entry")
int probe_softirq_entry(struct trace_event_raw_softirq *ctx)
{
    lat = bpf_map_lookup_elem(&softirq_percpu_lats, &ctx->vec);
    u64 latency = bpf_ktime_get_ns() - lat->timestamp;
    
    // åˆ†åŒºé—´ç´¯åŠ è®¡æ•° (ä½¿ç”¨åŸå­æ“ä½œ)
    if (latency < 10 * NSEC_PER_USEC) {
        __sync_fetch_and_add(&lat->total_latency[LAT_ZONE0], 1);
    } else if (latency < 100 * NSEC_PER_USEC) {
        __sync_fetch_and_add(&lat->total_latency[LAT_ZONE1], 1);
    }
    // ... å…¶ä»–åŒºé—´
}
```

**è®¾è®¡äº®ç‚¹**:
1. **ç›´æ–¹å›¾ç»Ÿè®¡**: å»¶è¿Ÿåˆ†4ä¸ªåŒºé—´ï¼Œæ¯”å•ä¸€å¹³å‡å€¼æ›´æœ‰ä»·å€¼
2. **Per-CPU**: é¿å…è·¨CPUåŒæ­¥ï¼Œæ— é”è®¾è®¡
3. **åŸå­æ“ä½œ**: `__sync_fetch_and_add` ä¿è¯å¹¶å‘å®‰å…¨
4. **ç”¨æˆ·æ€è½®è¯¢**: é€šè¿‡ DumpMap è¯»å–ç»Ÿè®¡æ•°æ®

---

### 10.3 å†…å­˜ç®¡ç†ç±»

#### 10.3.1 oom.c - OOM Killer ç›‘æ§

**åŠŸèƒ½**: ç›‘æ§ OOM (Out Of Memory) äº‹ä»¶ï¼Œè®°å½•è§¦å‘è€…å’Œè¢«æ€è¿›ç¨‹

**æŒ‚è½½ç‚¹**:
- `kprobe/oom_kill_process` - OOM Killer æ‰§è¡Œç‚¹

**æ ¸å¿ƒæ•°æ®ç»“æ„**:
```c
struct oom_info {
    char trigger_comm[16];      // è§¦å‘OOMçš„è¿›ç¨‹å
    char victim_comm[16];       // è¢«æ€è¿›ç¨‹å
    u32 trigger_pid;            // è§¦å‘è€…PID
    u32 victim_pid;             // è¢«æ€è€…PID
    u64 trigger_memcg_css;      // è§¦å‘è€…cgroup (memory)
    u64 victim_memcg_css;       // è¢«æ€è€…cgroup
};
```

**å®ç°é€»è¾‘**:
```c
SEC("kprobe/oom_kill_process")
int BPF_KPROBE(oom_kill_process, struct oom_control *oc, const char *message)
{
    if (bpf_ratelimited_in_map(ctx, rate))  // é™é€Ÿ
        return 0;
    
    // 1. è·å–è§¦å‘è€…ä¿¡æ¯ (å½“å‰ä»»åŠ¡)
    trigger_task = (struct task_struct *)bpf_get_current_task();
    info.trigger_pid = BPF_CORE_READ(trigger_task, pid);
    BPF_CORE_READ_STR_INTO(&info.trigger_comm, trigger_task, comm);
    
    // 2. è·å–è¢«æ€è€…ä¿¡æ¯ (oc->chosen)
    victim_task = BPF_CORE_READ(oc, chosen);
    info.victim_pid = BPF_CORE_READ(victim_task, pid);
    BPF_CORE_READ_STR_INTO(&info.victim_comm, victim_task, comm);
    
    // 3. è·å– Memory Cgroup ä¿¡æ¯
    info.victim_memcg_css = 
        (u64)BPF_CORE_READ(victim_task, cgroups, subsys[memory_cgrp_id]);
    
    bpf_perf_event_output(ctx, &oom_perf_events, ...);
}
```

**è®¾è®¡äº®ç‚¹**:
1. **åŒå‘è¿½è¸ª**: åŒæ—¶è®°å½•è§¦å‘è€…å’Œå—å®³è€…
2. **Cgroupå…³è”**: ä¾¿äºå®¹å™¨ç¯å¢ƒå®šä½é—®é¢˜
3. **Rate Limiting**: é˜²æ­¢OOMé£æš´å¯¼è‡´äº‹ä»¶æ´ªæ°´

**ä½¿ç”¨åœºæ™¯**:
- å®¹å™¨ OOM æ ¹å› åˆ†æ
- å†…å­˜æ³„æ¼æ£€æµ‹
- Cgroup å†…å­˜é™åˆ¶è°ƒä¼˜

---

#### 10.3.2 hungtask.c - æŒ‚èµ·ä»»åŠ¡æ£€æµ‹

**åŠŸèƒ½**: æ£€æµ‹é•¿æ—¶é—´å¤„äºä¸å¯ä¸­æ–­ç¡çœ çŠ¶æ€ (TASK_UNINTERRUPTIBLE) çš„ä»»åŠ¡

**æŒ‚è½½ç‚¹**:
- `tracepoint/sched/sched_process_hang` - å†…æ ¸æŒ‚èµ·ä»»åŠ¡æ£€æµ‹å™¨è§¦å‘

**æ ¸å¿ƒå®ç°**:
```c
struct hungtask_info {
    int32_t pid;
    char comm[16];
};

SEC("tracepoint/sched/sched_process_hang")
int tracepoint_sched_process_hang(...) {
    struct hungtask_info info = {};
    
    info.pid = ctx->pid;
    BPF_CORE_READ_STR_INTO(&info.comm, ctx, comm);
    
    bpf_perf_event_output(ctx, &hungtask_perf_events, ...);
}
```

**ç‰¹ç‚¹**:
- æç®€å®ç° (33è¡Œ)
- ä¾èµ–å†…æ ¸ hung_task æœºåˆ¶ (é»˜è®¤120ç§’è¶…æ—¶)
- é€šå¸¸ç”± IO é˜»å¡ã€æ­»é”å¼•èµ·

---

#### 10.3.3 softlockup.c - è½¯é”æ£€æµ‹

**åŠŸèƒ½**: æ£€æµ‹ CPU é•¿æ—¶é—´ä¸å“åº”è°ƒåº¦ (soft lockup)

**æŒ‚è½½ç‚¹**:
- `kprobe/add_taint` - å†…æ ¸æ ‡è®°æ±¡æŸ“çŠ¶æ€æ—¶è§¦å‘

**æ ¸å¿ƒå®ç°**:
```c
struct softlockup_info {
    u32 cpu;        // å‘ç”Ÿé”çš„CPU
    u32 pid;        // å ç”¨CPUçš„è¿›ç¨‹
    char comm[16];
};

SEC("kprobe/add_taint")
int kprobe_softlockup(struct pt_regs *ctx)
{
    // åªç›‘å¬ TAINT_SOFTLOCKUP æ ‡å¿—
    if (PT_REGS_PARM1(ctx) != TAINT_SOFTLOCKUP)
        return 0;
    
    struct softlockup_info info = {
        .cpu = bpf_get_smp_processor_id(),
        .pid = bpf_get_current_pid_tgid() >> 32,
    };
    
    struct task_struct *task = bpf_get_current_task();
    BPF_CORE_READ_STR_INTO(&info.comm, task, comm);
    
    bpf_perf_event_output(ctx, &softlockup_perf_events, ...);
}
```

**è®¾è®¡è¯´æ˜**:
- åˆ©ç”¨å†…æ ¸ soft lockup detector
- é»˜è®¤é˜ˆå€¼: 20ç§’æ— è°ƒåº¦
- é€šå¸¸ç”±æ­»å¾ªç¯ã€è¿‡é•¿ä¸­æ–­å¤„ç†å¼•èµ·

---

### 10.4 æ€§èƒ½å¯¹æ¯”æ€»ç»“

| ç¨‹åº | Mapç±»å‹ | æ•°æ®ä¼ é€’ | ç»Ÿè®¡æ–¹å¼ | é€‚ç”¨åœºæ™¯ |
|------|---------|----------|----------|----------|
| **dropwatch** | Perf Event Array | äº‹ä»¶æµ | å®æ—¶ | æ•…éšœè¯Šæ–­ |
| **netrecvlat** | Perf Event Array | äº‹ä»¶æµ | å®æ—¶ | å»¶è¿Ÿåˆ†æ |
| **netdev_hw** | Hash Map | è½®è¯¢ | èšåˆ | æŒ‡æ ‡é‡‡é›† |
| **lacp** | Perf Event Array | äº‹ä»¶é€šçŸ¥ | äº‹ä»¶è§¦å‘ | çŠ¶æ€ç›‘æ§ |
| **softirq** | Per-CPU Array | è½®è¯¢ | ç›´æ–¹å›¾ | æ€§èƒ½åˆ†æ |
| **runqlat_tracing** | Hash Map | è½®è¯¢ | ç›´æ–¹å›¾ | è°ƒåº¦åˆ†æ |
| **oom** | Perf Event Array | äº‹ä»¶æµ | å®æ—¶ | å†…å­˜é—®é¢˜ |
| **hungtask** | Perf Event Array | äº‹ä»¶æµ | å®æ—¶ | IOé˜»å¡ |
| **softlockup** | Perf Event Array | äº‹ä»¶æµ | å®æ—¶ | CPUæ­»é” |

### 10.5 å…¬å…±å¤´æ–‡ä»¶åˆ†æ

#### bpf_common.h
```c
#define COMPAT_BPF_F_CURRENT_CPU 0xffffffffULL
#define COMPAT_TASK_COMM_LEN   16
#define PATH_MAX        4096
#define COMPAT_CPU_NUM 128
#define PERF_MAX_STACK_DEPTH	127  // æœ€å¤§æ ˆæ·±åº¦

// Map æ“ä½œæ ‡å¿—
#define COMPAT_BPF_ANY		0  // åˆ›å»ºæˆ–æ›´æ–°
#define COMPAT_BPF_NOEXIST	1  // ä»…åˆ›å»º
#define COMPAT_BPF_EXIST	2  // ä»…æ›´æ–°
```

#### bpf_ratelimit.h
æä¾›ä¸¤ç§ Rate Limiting å®ç°ï¼š
```c
// 1. ç®€å•ç‰ˆæœ¬ï¼šæ¯ç§’æœ€å¤šNä¸ªäº‹ä»¶
BPF_RATELIMIT(name, 1, 100);  // 100/ç§’

// 2. Per-CPUç‰ˆæœ¬ï¼šä½¿ç”¨Mapå­˜å‚¨çŠ¶æ€
BPF_RATELIMIT_IN_MAP(name, 1, COMPAT_CPU_NUM * 10000, 0);
```

å®ç°åŸç†ï¼š
- ä½¿ç”¨æ»‘åŠ¨æ—¶é—´çª—å£
- Per-CPU è®¡æ•°å™¨é¿å…ç«äº‰
- è¶…é™åç›´æ¥è¿”å›ï¼Œä¿æŠ¤ç³»ç»Ÿ

---

**ä¸‹ä¸€æ­¥å»ºè®®**:
1. æŸ¥çœ‹ç”¨æˆ·æ€å¯¹åº”çš„ Go ä»£ç  (core/events/*.go)
2. ç†è§£ Map æ•°æ®å¦‚ä½•è¢«ç”¨æˆ·æ€è¯»å–
3. åˆ†æå­˜å‚¨å±‚å¦‚ä½•æŒä¹…åŒ–è¿™äº›äº‹ä»¶
