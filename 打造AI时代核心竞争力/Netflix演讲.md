# 不要外包你的思考：在AI编程时代保持理解力

## 开场白

大家好，下午好。我想以一个坦白来开始我的演讲：我曾经发布过自己不太理解的代码。生成它，测试它，部署它，但没法解释它是怎么工作的。我敢打赌，你们每个人也都干过这事。

所以现在我要承认，我们都在发布自己不再理解的代码。我想带大家回顾一下，看看我们是怎么走到这一步的。

首先，回顾历史，我们会发现历史总在重演。其次，我们掉进了一个陷阱，把"容易"和"简单"搞混了。最后，确实有解决办法，但前提是我们不能把思考外包出去。

## AI带来的加速效果是真的

过去几年我在Netflix帮助推动AI工具的采用，我得说，加速效果确实很明显。以前要花好几天的任务，现在几个小时就搞定了；搁置多年的大型重构终于能做了。

但大型生产系统总是以你想不到的方式出问题。看看最近CloudFlare那次事故。系统挂了的时候，你最好能看懂你在调试的代码。而现在呢，我们生成代码的速度太快、量太大，理解能力根本跟不上。

说实话，我自己也这样。生成了一堆代码，看了看，心想：这玩意儿到底干啥的？但测试过了，能跑，那就发布吧。

其实这不是什么新鲜事。每一代软件工程师最后都会撞上这堵墙：软件复杂度超出了他们的掌控能力。我们不是第一批面对软件危机的人，但我们是第一批在"无限生成"这个规模下面对它的人。

## 软件危机简史

让我们往回看看，这一切是怎么开始的。

60年代末、70年代初，一群聪明的计算机科学家凑在一起说："我们遇到软件危机了。软件需求这么大，但我们跟不上，项目拖太久，效率太低。"

Dijkstra说过一句话："当我们只有几台弱鸡电脑的时候，编程是个小问题；现在我们有了巨型计算机，编程变成了巨型问题。"他的意思是，硬件能力涨了一千倍，社会对软件的需求也跟着涨了一千倍，留给程序员的难题就是：怎么支撑这么多软件？

这种循环一直在重复：

- **70年代**：有了C语言，能写更大的系统了
- **80年代**：个人电脑普及，人人都能写代码了
- **90年代**：面向对象编程，带来了地狱级的继承层次（谢谢Java）
- **2000年代**：敏捷开发来了，冲刺、Scrum Master，瀑布模式被抛弃
- **2010年代**：云、移动、DevOps，软件真的吞噬了世界
- **今天**：AI时代，Copilot、Cursor、Claude、Codex、Gemini……想要什么代码，描述一下就有了

这个模式还在继续。

## 没有银弹

Fred Brooks，就是写《人月神话》那位，他在1986年还写过一篇论文叫《没有银弹》。他认为不会有任何单一的创新能让软件生产力提升一个数量级。

为什么？因为他说，**困难的部分从来不是写代码这个动作本身，不是语法、不是敲键盘、不是模板代码。真正难的是理解问题、设计方案。这个根本性的困难，任何工具都消除不了。** 我们发明的所有工具和技术，都只是让"写"这个动作变简单了，但核心挑战没变：搞清楚要建什么、它该怎么运作。

## 简单与容易的区别

既然问题不在写代码这个动作上，那我们为什么还在不停优化它？有经验的工程师怎么会写出自己都看不懂的代码？

我觉得答案在于我们搞混了两个词：**简单（simple）和容易（easy）**。

我们老把这俩词混着用，但它们意思完全不一样。

Clojure的作者Rich Hickey在2011年有个演讲叫"Simple Made Easy"，他是这么定义的：

- **简单**：单一、不纠缠，每个部分只干一件事，不跟别的部分搅在一起
- **容易**：触手可及，不费劲就能拿到。复制、粘贴、发布

简单是结构问题，容易是距离问题。

你没法靠许愿让一个东西变简单。简单需要思考、设计、解开那些纠缠。但让东西变容易永远都行：装个包，让AI生成，从Stack Overflow抄一个。

人天生就想走容易的路，这是本能。但容易不等于简单。容易意味着你能快速往系统里加东西，简单意味着你能理解自己干了什么。每次选容易，就是选了"现在快、以后乱"。

说实话，以前这个取舍还行得通。复杂度在代码库里积累得够慢，需要的时候还能重构、重新设计。但AI打破了这个平衡，因为它是终极的"容易按钮"。它让容易的路顺滑到你根本不会去想简单的路。代码秒出，谁还考虑架构？

## 复杂性怎么失控的

让我演示一下这是怎么发生的。

举个例子，假设我们有个应用，想加身份验证。跟AI说"加个auth"，得到一个干净的auth.js。迭代几次，又多了个message文件。行，挺好。再加OAuth，现在有auth.js和OAuth.js了。继续迭代，然后发现session坏了，一堆冲突。

到了第20轮对话，你已经不是在讨论了，你在管理一个复杂到连自己都记不清所有约束的上下文。被放弃的方案留下的死代码，为了让测试通过而硬改的测试，三个不同方案的碎片混在一起，因为每条新指令都在覆盖之前的架构。

我们说"让auth能用"，它做到了。我们说"修这个bug"，它也做到了。烂架构没有任何阻力，代码就这么变形去满足你最新的要求。每次交互都在选容易、放弃简单。容易永远意味着更多复杂度。我们心里清楚，但容易的路太容易了，就是会选它。复杂度一直累积，直到来不及了。

## AI把"容易"推到了极致

AI真的把容易推到了逻辑的尽头。想要什么，说一声，代码立刻就有。但危险在于：生成的代码把代码库里的每个模式都一视同仁。

AI agent分析你的代码库时，每一行都变成了要保留的模式。第47行的权限检查是模式，2019年写的那段像GraphQL一样用的gRPC代码也是模式。技术债不会被识别成债，它就是更多代码而已。

这里真正的麻烦是复杂性。最好的理解方式是：它是简单的反面，意味着东西缠在一起。一旦复杂了，什么都跟什么都有关系，改一个地方要影响十个地方。

## 本质复杂度与偶然复杂度

回到Fred Brooks的《没有银弹》。他说每个系统里有两种复杂性：

1. **本质复杂度**：你要解决的问题本身的难度。用户要付款，订单要发货。这是你的软件存在的理由。

2. **偶然复杂度**：一路上加进去的其他东西。改变方案、防御性代码、框架、当时觉得合理的抽象，其实这些是为了让代码跑起来而拼凑的东西。

真实代码库里，这两种复杂性到处都是，缠得死死的。要分开它们，需要上下文、历史、经验。AI生成的输出不做这种区分，所有模式都被原样保留。

## Netflix的真实案例

说个我们在Netflix遇到的真事。我有个系统，中间有一层抽象，夹在五年前写的旧授权代码和新的集中式auth系统之间。当时没时间重写整个应用，就加了个垫片凑合用。

现在有AI了，正好可以重构，直接用新系统。听起来挺简单吧？

不。旧代码跟授权逻辑耦合得太紧了。权限检查散在业务逻辑里，角色假设写死在数据模型里，auth调用分布在几百个文件中。AI agent开始重构，搞了几个文件就碰到解不开的依赖，然后失控放弃。更糟的是，它有时候会试图保留旧系统的逻辑，用新系统重新实现一遍，这也不行。

它看不到边界在哪。它分不清业务逻辑在哪结束、auth逻辑从哪开始。所有东西缠得太紧，就算信息完整，AI也找不到一条干净的路。偶然复杂度一旦缠成这样，AI帮不了你，只会在上面再加几层。

我们能分得清，至少慢下来想的时候能分清。我们知道哪些模式是本质的，哪些只是当年某人的临时方案。我们脑子里有AI能推断但推断不出来的上下文，但得在动手之前花时间把这些区分出来。

## 三阶段方法

那具体怎么做？面对一个巨大的代码库，怎么分开偶然复杂度和本质复杂度？

我在Netflix的代码库大概有一百万行Java，main service主服务大概500万token。目前ai agent的上下文窗口都装不下。

一开始我想，也许把代码库的大块内容塞进上下文，看看能不能跑出点模式来。跟之前授权重构那次一样，输出迷失在自己的复杂度里了。

所以我只好换个做法。我得挑选要放什么进去：设计文档、架构图、关键接口，然后花时间写清楚组件怎么交互、该遵循什么模式。

其实我是在写spec规格说明。

500万token变成了2000字的规格。然后再进一步，把规格变成一组精确的执行步骤。不要模糊的指令，就是精确的操作序列。这样出来的代码干净多了、聚焦多了，我也能看懂，因为我先定义了它、规划了执行。

这就是我说的"上下文压缩"。你也可以叫它上下文工程、规格驱动开发，叫什么无所谓。重要的是：**思考和规划成了大部分工作**。

### 第一阶段：研究

一上来就把所有东西喂给AI：架构图、文档、Slack里的讨论。尽量带上跟你要改的东西相关的上下文，然后让agent分析代码库、画出组件和依赖关系。

这不是一锤子买卖。我会追问："缓存那块呢？失败怎么处理？"分析错了我就纠正，缺上下文我就补。每轮迭代都在纠正和完善AI对于代码库的分析。

这一步的输出是一份研究文档：有什么、什么连着什么、你的改动会影响什么。几小时的探索压缩成几分钟的阅读。

人工检查点很关键。这是你拿分析结果跟现实对照的时候，是整个流程里收益最高的环节。在这里抓住错误，后面就不会出灾难。

### 第二阶段：规划

研究做完了，就做详细的实施计划：具体的代码结构、函数签名、类型定义、数据流向。详细到任何开发者都能照着做。我把它比作填色画：你应该能把它交给最初级的工程师说"去做"，他照着一行行抄，就应该能跑。

这一步做很多重要的架构决策。复杂逻辑对不对？业务需求符不符合好的实践？服务边界清不清楚？有没有不必要的耦合？我们能在问题出现之前发现它们，因为我们踩过坑。AI没这个经验，它把每个模式都当成需求。

这一步的价值在于审查速度。几分钟就能验证计划、知道要建什么。要跟上生成代码的速度，我们理解代码的速度也得跟上。

### 第三阶段：实施

有了清晰的研究和计划，这一步就该很简单了。这正是目的。AI有明确的规格可以遵循，上下文保持干净、聚焦。我们避免了长对话带来的复杂度螺旋。

不是50条消息来来回回改代码，而是三个聚焦的输出，每个都在继续前验证过。没有被放弃的方案，没有冲突的模式，没有"等等其实……"留下的死代码。

真正的回报是你可以让后台agent做很多活，因为思考和硬活你已经提前做完了。它直接开始实施，你可以去干别的，回来再审。审查会很快，因为你只是在核对它有没有按计划来，不用去理解它发明了什么新东西。

关键是：**我们不是让AI替我们思考，而是用它加速机械的部分，同时保住我们的理解能力**。研究更快，规划更周全，实施更干净。但思考、综合、判断，还是我们的事。

## 有时候你得先手动做一遍

还记得我说AI搞不定的那个授权重构吗？我们现在在做了，开始有进展了。但不是因为找到了更好的提示词。

我们发现连研究、规划、实施都没法直接开始。我们得先自己手动改一遍，不用AI，就是读代码、理解依赖、改东西看什么会坏。

那次手动迁移，说实话，很痛苦，但非常关键。它暴露了所有隐藏的约束：哪些不变量必须保持、改auth会搞坏哪些服务。这些东西再多的代码分析都分析不出来。

然后我们把那个手动迁移的PR喂给AI的研究流程，让它作为后续研究的种子。这样AI就能看到一次干净的迁移长什么样。但每个实体都有点不一样，所以我们得不断追问："这个怎么办？"有些东西加密了，有些没有。每次都得补额外的上下文，反复迭代。

只有这样，我们才能生成一个可能一次跑通的计划。注意是"可能"，我们还在验证、还在调整、还在发现边缘情况。

三阶段方法不是魔法。它能用，是因为我们先手动做了一次迁移。**我们得先赢得理解，才能把它编进流程里。** 我还是认为没有银弹。不是更好的提示词，不是更好的模型，甚至不是更好的规格说明，就是得深入理解你的系统，才能安全地改它。

## 知识鸿沟

那为什么要费这个劲？为什么不直接跟AI反复迭代直到能用？模型不是会越来越强，最后总能行吗？

对我来说，"能用"不够。通过测试的代码和在生产环境活下来的代码是两回事。今天能跑的系统和将来别人还能改的系统是两回事。

真正的麻烦是知识鸿沟。AI几秒钟生成几千行代码，你要理解它可能要几小时，复杂的话要几天，缠得太紧的话可能永远也理解不了。

有件事我觉得很多人都没在讨论：**每次我们为了跟上生成速度而跳过思考，我们不只是在加不懂的代码，我们在丧失识别问题的能力。** 那种"感觉这里越来越复杂了"的直觉，你不理解自己的系统，它就会退化。

模式识别来自经验。我能发现危险的架构，是因为我凌晨三点爬起来处理过。我推动更简单的方案，是因为我维护过别人留下的复杂方案。AI生成你要的东西，但它不会把过去的教训编进去。

三阶段方法弥补了这个鸿沟。它把理解压缩成我们能以生成速度审查的产物。没有它，我们只是在以超过理解能力的速度堆积复杂度。

## 结论

AI改变了我们写代码的方式，但说实话，我不觉得它改变了软件为什么会失败。每一代人都有自己的软件危机。Dijkstra那代人靠创立软件工程这门学科来应对，现在轮到我们面对无限代码生成了。

我不觉得答案是另一个工具或方法论，而是记住我们一直知道的事：**软件是人的事。难的从来不是敲代码，而是知道该敲什么。**

能成功的开发者不会是生成代码最多的人，而是理解自己在建什么的人，是还能看到边界的人，是能意识到自己在解决错误问题的人。这还是我们的事。只能是我们的事。

我想用一个问题结束。我觉得问题不是我们会不会用AI，那已经是定局了，船已经开了。对我来说，问题是：

**当AI写了我们大部分代码的时候，我们还能理解自己的系统吗？**

谢谢大家。
